{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GRU.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMyKO2aIlvkP/x6fW45ieoH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SVGS-EVA4/Phase2/blob/master/S11-GRU%2C_Attention_Mechanism_%26_Transformers/GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bWwI_dbP5gT"
      },
      "source": [
        "Code From:\n",
        "\n",
        "J. Bastings. 2018. The Annotated Encoder-Decoder with Attention. https://bastings.github.io/annotated_encoder_decoder/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cNaJDHZOKEnJ",
        "outputId": "6a640b03-b0e2-404e-d791-512cbc7d19f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "!pip install torch==1.5.1+cu92 torchvision==0.6.1+cu92 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torch-1.5.1%2Bcu92-cp36-cp36m-linux_x86_64.whl (604.8MB)\n",
            "\u001b[K     |████████████████████████████████| 604.8MB 28kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu92\n",
            "\u001b[?25l  Downloading https://download.pytorch.org/whl/cu92/torchvision-0.6.1%2Bcu92-cp36-cp36m-linux_x86_64.whl (6.5MB)\n",
            "\u001b[K     |████████████████████████████████| 6.5MB 11.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu92) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch==1.5.1+cu92) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision==0.6.1+cu92) (7.0.0)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Found existing installation: torch 1.6.0+cu101\n",
            "    Uninstalling torch-1.6.0+cu101:\n",
            "      Successfully uninstalled torch-1.6.0+cu101\n",
            "  Found existing installation: torchvision 0.7.0+cu101\n",
            "    Uninstalling torchvision-0.7.0+cu101:\n",
            "      Successfully uninstalled torchvision-0.7.0+cu101\n",
            "Successfully installed torch-1.5.1+cu92 torchvision-0.6.1+cu92\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yxcJmFT4OAyJ",
        "outputId": "527d15eb-e1a9-4818-87fc-10b431db8b89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import math, copy, time\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "from IPython.core.debugger import set_trace\n",
        "\n",
        "# we will use CUDA if it is available\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE=torch.device('cuda:0') # or set to 'cpu'\n",
        "print(\"CUDA:\", USE_CUDA)\n",
        "print(DEVICE)\n",
        "\n",
        "seed = 42\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "torch.cuda.manual_seed(seed)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA: True\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGQrA6DoOM35"
      },
      "source": [
        "class EncoderDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A standard Encoder-Decoder architecture. Base for this and many \n",
        "    other models.\n",
        "    \"\"\"\n",
        "    def __init__(self, encoder, decoder, src_embed, trg_embed, generator):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        self.src_embed = src_embed\n",
        "        self.trg_embed = trg_embed\n",
        "        self.generator = generator\n",
        "        \n",
        "    def forward(self, src, trg, src_mask, trg_mask, src_lengths, trg_lengths):\n",
        "        \"\"\"Take in and process masked src and target sequences.\"\"\"\n",
        "        encoder_hidden, encoder_final = self.encode(src, src_mask, src_lengths)\n",
        "        return self.decode(encoder_hidden, encoder_final, src_mask, trg, trg_mask)\n",
        "    \n",
        "    def encode(self, src, src_mask, src_lengths):\n",
        "        return self.encoder(self.src_embed(src), src_mask, src_lengths)\n",
        "    \n",
        "    def decode(self, encoder_hidden, encoder_final, src_mask, trg, trg_mask,\n",
        "               decoder_hidden=None):\n",
        "        return self.decoder(self.trg_embed(trg), encoder_hidden, encoder_final,\n",
        "                            src_mask, trg_mask, hidden=decoder_hidden)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2K31QKjPOQIK"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    \"\"\"Define standard linear + softmax generation step.\"\"\"\n",
        "    def __init__(self, hidden_size, vocab_size):\n",
        "        super(Generator, self).__init__()\n",
        "        self.proj = nn.Linear(hidden_size, vocab_size, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return F.log_softmax(self.proj(x), dim=-1)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aZMWbPVoOd7Y"
      },
      "source": [
        "class Encoder(nn.Module):\n",
        "    \"\"\"Encodes a sequence of word embeddings\"\"\"\n",
        "    def __init__(self, input_size, hidden_size, num_layers=1, dropout=0.):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.rnn = nn.GRU(input_size, hidden_size, num_layers, \n",
        "                          batch_first=True, bidirectional=True, dropout=dropout)\n",
        "        \n",
        "    def forward(self, x, mask, lengths):\n",
        "        \"\"\"\n",
        "        Applies a bidirectional GRU to sequence of embeddings x.\n",
        "        The input mini-batch x needs to be sorted by length.\n",
        "        x should have dimensions [batch, time, dim].\n",
        "        \"\"\"\n",
        "        packed = pack_padded_sequence(x, lengths, batch_first=True)\n",
        "        output, final = self.rnn(packed)\n",
        "        output, _ = pad_packed_sequence(output, batch_first=True)\n",
        "\n",
        "        # we need to manually concatenate the final states for both directions\n",
        "        fwd_final = final[0:final.size(0):2]\n",
        "        bwd_final = final[1:final.size(0):2]\n",
        "        final = torch.cat([fwd_final, bwd_final], dim=2)  # [num_layers, batch, 2*dim]\n",
        "\n",
        "        return output, final"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jC5DgpIqOhe6"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\"A conditional RNN decoder with attention.\"\"\"\n",
        "    \n",
        "    def __init__(self, emb_size, hidden_size, attention, num_layers=1, dropout=0.5,\n",
        "                 bridge=True):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.attention = attention\n",
        "        self.dropout = dropout\n",
        "                 \n",
        "        self.rnn = nn.GRU(emb_size + 2*hidden_size, hidden_size, num_layers,\n",
        "                          batch_first=True, dropout=dropout)\n",
        "                 \n",
        "        # to initialize from the final encoder state\n",
        "        self.bridge = nn.Linear(2*hidden_size, hidden_size, bias=True) if bridge else None\n",
        "\n",
        "        self.dropout_layer = nn.Dropout(p=dropout)\n",
        "        self.pre_output_layer = nn.Linear(hidden_size + 2*hidden_size + emb_size,\n",
        "                                          hidden_size, bias=False)\n",
        "        \n",
        "    def forward_step(self, prev_embed, encoder_hidden, src_mask, proj_key, hidden):\n",
        "        \"\"\"Perform a single decoder step (1 word)\"\"\"\n",
        "\n",
        "        # compute context vector using attention mechanism\n",
        "        query = hidden[-1].unsqueeze(1)  # [#layers, B, D] -> [B, 1, D]\n",
        "        context, attn_probs = self.attention(\n",
        "            query=query, proj_key=proj_key,\n",
        "            value=encoder_hidden, mask=src_mask)\n",
        "\n",
        "        # update rnn hidden state\n",
        "        rnn_input = torch.cat([prev_embed, context], dim=2)\n",
        "        output, hidden = self.rnn(rnn_input, hidden)\n",
        "        \n",
        "        pre_output = torch.cat([prev_embed, output, context], dim=2)\n",
        "        pre_output = self.dropout_layer(pre_output)\n",
        "        pre_output = self.pre_output_layer(pre_output)\n",
        "\n",
        "        return output, hidden, pre_output\n",
        "    \n",
        "    def forward(self, trg_embed, encoder_hidden, encoder_final, \n",
        "                src_mask, trg_mask, hidden=None, max_len=None):\n",
        "        \"\"\"Unroll the decoder one step at a time.\"\"\"\n",
        "                                         \n",
        "        # the maximum number of steps to unroll the RNN\n",
        "        if max_len is None:\n",
        "            max_len = trg_mask.size(-1)\n",
        "\n",
        "        # initialize decoder hidden state\n",
        "        if hidden is None:\n",
        "            hidden = self.init_hidden(encoder_final)\n",
        "        \n",
        "        # pre-compute projected encoder hidden states\n",
        "        # (the \"keys\" for the attention mechanism)\n",
        "        # this is only done for efficiency\n",
        "        proj_key = self.attention.key_layer(encoder_hidden)\n",
        "        \n",
        "        # here we store all intermediate hidden states and pre-output vectors\n",
        "        decoder_states = []\n",
        "        pre_output_vectors = []\n",
        "        \n",
        "        # unroll the decoder RNN for max_len steps\n",
        "        for i in range(max_len):\n",
        "            prev_embed = trg_embed[:, i].unsqueeze(1)\n",
        "            output, hidden, pre_output = self.forward_step(\n",
        "              prev_embed, encoder_hidden, src_mask, proj_key, hidden)\n",
        "            decoder_states.append(output)\n",
        "            pre_output_vectors.append(pre_output)\n",
        "\n",
        "        decoder_states = torch.cat(decoder_states, dim=1)\n",
        "        pre_output_vectors = torch.cat(pre_output_vectors, dim=1)\n",
        "        return decoder_states, hidden, pre_output_vectors  # [B, N, D]\n",
        "\n",
        "    def init_hidden(self, encoder_final):\n",
        "        \"\"\"Returns the initial decoder state,\n",
        "        conditioned on the final encoder state.\"\"\"\n",
        "\n",
        "        if encoder_final is None:\n",
        "            return None  # start with zeros\n",
        "\n",
        "        return torch.tanh(self.bridge(encoder_final))            \n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jch7ro_hOks2"
      },
      "source": [
        "class BahdanauAttention(nn.Module):\n",
        "    \"\"\"Implements Bahdanau (MLP) attention\"\"\"\n",
        "    \n",
        "    def __init__(self, hidden_size, key_size=None, query_size=None):\n",
        "        super(BahdanauAttention, self).__init__()\n",
        "        \n",
        "        # We assume a bi-directional encoder so key_size is 2*hidden_size\n",
        "        key_size = 2 * hidden_size if key_size is None else key_size\n",
        "        query_size = hidden_size if query_size is None else query_size\n",
        "\n",
        "        self.key_layer = nn.Linear(key_size, hidden_size, bias=False)\n",
        "        self.query_layer = nn.Linear(query_size, hidden_size, bias=False)\n",
        "        self.energy_layer = nn.Linear(hidden_size, 1, bias=False)\n",
        "        \n",
        "        # to store attention scores\n",
        "        self.alphas = None\n",
        "        \n",
        "    def forward(self, query=None, proj_key=None, value=None, mask=None):\n",
        "        assert mask is not None, \"mask is required\"\n",
        "\n",
        "        # We first project the query (the decoder state).\n",
        "        # The projected keys (the encoder states) were already pre-computated.\n",
        "        query = self.query_layer(query)\n",
        "        \n",
        "        # Calculate scores.\n",
        "        scores = self.energy_layer(torch.tanh(query + proj_key))\n",
        "        scores = scores.squeeze(2).unsqueeze(1)\n",
        "        \n",
        "        # Mask out invalid positions.\n",
        "        # The mask marks valid positions so we invert it using `mask & 0`.\n",
        "        scores.data.masked_fill_(mask == 0, -float('inf'))\n",
        "        \n",
        "        # Turn scores to probabilities.\n",
        "        alphas = F.softmax(scores, dim=-1)\n",
        "        self.alphas = alphas        \n",
        "        \n",
        "        # The context vector is the weighted sum of the values.\n",
        "        context = torch.bmm(alphas, value)\n",
        "        \n",
        "        # context shape: [B, 1, 2D], alphas shape: [B, 1, M]\n",
        "        return context, alphas"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHK925e8OmqB"
      },
      "source": [
        "def make_model(src_vocab, tgt_vocab, emb_size=256, hidden_size=512, num_layers=1, dropout=0.1):\n",
        "    \"Helper: Construct a model from hyperparameters.\"\n",
        "\n",
        "    attention = BahdanauAttention(hidden_size)\n",
        "\n",
        "    model = EncoderDecoder(\n",
        "        Encoder(emb_size, hidden_size, num_layers=num_layers, dropout=dropout),\n",
        "        Decoder(emb_size, hidden_size, attention, num_layers=num_layers, dropout=dropout),\n",
        "        nn.Embedding(src_vocab, emb_size),\n",
        "        nn.Embedding(tgt_vocab, emb_size),\n",
        "        Generator(hidden_size, tgt_vocab))\n",
        "\n",
        "    return model.cuda() if USE_CUDA else model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bE1BUNkVOpJc"
      },
      "source": [
        "class Batch:\n",
        "    \"\"\"Object for holding a batch of data with mask during training.\n",
        "    Input is a batch from a torch text iterator.\n",
        "    \"\"\"\n",
        "    def __init__(self, src, trg, pad_index=0):\n",
        "        \n",
        "        src, src_lengths = src\n",
        "        \n",
        "        self.src = src\n",
        "        self.src_lengths = src_lengths\n",
        "        self.src_mask = (src != pad_index).unsqueeze(-2)\n",
        "        self.nseqs = src.size(0)\n",
        "        \n",
        "        self.trg = None\n",
        "        self.trg_y = None\n",
        "        self.trg_mask = None\n",
        "        self.trg_lengths = None\n",
        "        self.ntokens = None\n",
        "\n",
        "        if trg is not None:\n",
        "            trg, trg_lengths = trg\n",
        "            self.trg = trg[:, :-1]\n",
        "            self.trg_lengths = trg_lengths\n",
        "            self.trg_y = trg[:, 1:]\n",
        "            self.trg_mask = (self.trg_y != pad_index)\n",
        "            self.ntokens = (self.trg_y != pad_index).data.sum().item()\n",
        "        \n",
        "        if USE_CUDA:\n",
        "            self.src = self.src.cuda()\n",
        "            self.src_mask = self.src_mask.cuda()\n",
        "\n",
        "            if trg is not None:\n",
        "                self.trg = self.trg.cuda()\n",
        "                self.trg_y = self.trg_y.cuda()\n",
        "                self.trg_mask = self.trg_mask.cuda()"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJcRyE6XOrhs"
      },
      "source": [
        "def run_epoch(data_iter, model, loss_compute, print_every=50):\n",
        "    \"\"\"Standard Training and Logging Function\"\"\"\n",
        "\n",
        "    start = time.time()\n",
        "    total_tokens = 0\n",
        "    total_loss = 0\n",
        "    print_tokens = 0\n",
        "\n",
        "    for i, batch in enumerate(data_iter, 1):\n",
        "        \n",
        "        out, _, pre_output = model.forward(batch.src, batch.trg,\n",
        "                                           batch.src_mask, batch.trg_mask,\n",
        "                                           batch.src_lengths, batch.trg_lengths)\n",
        "        loss = loss_compute(pre_output, batch.trg_y, batch.nseqs)\n",
        "        total_loss += loss\n",
        "        total_tokens += batch.ntokens\n",
        "        print_tokens += batch.ntokens\n",
        "        \n",
        "        if model.training and i % print_every == 0:\n",
        "            elapsed = time.time() - start\n",
        "            print(\"Epoch Step: %d Loss: %f Tokens per Sec: %f\" %\n",
        "                    (i, loss / batch.nseqs, print_tokens / elapsed))\n",
        "            start = time.time()\n",
        "            print_tokens = 0\n",
        "\n",
        "    return math.exp(total_loss / float(total_tokens))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhICZwq1Ovgw"
      },
      "source": [
        "def data_gen(num_words=11, batch_size=16, num_batches=100, length=10, pad_index=0, sos_index=1):\n",
        "    \"\"\"Generate random data for a src-tgt copy task.\"\"\"\n",
        "    for i in range(num_batches):\n",
        "        data = torch.from_numpy(\n",
        "          np.random.randint(1, num_words, size=(batch_size, length)))\n",
        "        data[:, 0] = sos_index\n",
        "        data = data.cuda() if USE_CUDA else data\n",
        "        src = data[:, 1:]\n",
        "        trg = data\n",
        "        src_lengths = [length-1] * batch_size\n",
        "        trg_lengths = [length] * batch_size\n",
        "        yield Batch((src, src_lengths), (trg, trg_lengths), pad_index=pad_index)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M4vKKHQjOx_3"
      },
      "source": [
        "class SimpleLossCompute:\n",
        "    \"\"\"A simple loss compute and train function.\"\"\"\n",
        "\n",
        "    def __init__(self, generator, criterion, opt=None):\n",
        "        self.generator = generator\n",
        "        self.criterion = criterion\n",
        "        self.opt = opt\n",
        "\n",
        "    def __call__(self, x, y, norm):\n",
        "        x = self.generator(x)\n",
        "        loss = self.criterion(x.contiguous().view(-1, x.size(-1)),\n",
        "                              y.contiguous().view(-1))\n",
        "        loss = loss / norm\n",
        "\n",
        "        if self.opt is not None:\n",
        "            loss.backward()          \n",
        "            self.opt.step()\n",
        "            self.opt.zero_grad()\n",
        "\n",
        "        return loss.data.item() * norm"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFSJw6zXO1V3"
      },
      "source": [
        "def greedy_decode(model, src, src_mask, src_lengths, max_len=100, sos_index=1, eos_index=None):\n",
        "    \"\"\"Greedily decode a sentence.\"\"\"\n",
        "\n",
        "    with torch.no_grad():\n",
        "        encoder_hidden, encoder_final = model.encode(src, src_mask, src_lengths)\n",
        "        prev_y = torch.ones(1, 1).fill_(sos_index).type_as(src)\n",
        "        trg_mask = torch.ones_like(prev_y)\n",
        "\n",
        "    output = []\n",
        "    attention_scores = []\n",
        "    hidden = None\n",
        "\n",
        "    for i in range(max_len):\n",
        "        with torch.no_grad():\n",
        "            out, hidden, pre_output = model.decode(\n",
        "              encoder_hidden, encoder_final, src_mask,\n",
        "              prev_y, trg_mask, hidden)\n",
        "\n",
        "            # we predict from the pre-output layer, which is\n",
        "            # a combination of Decoder state, prev emb, and context\n",
        "            prob = model.generator(pre_output[:, -1])\n",
        "\n",
        "        _, next_word = torch.max(prob, dim=1)\n",
        "        next_word = next_word.data.item()\n",
        "        output.append(next_word)\n",
        "        prev_y = torch.ones(1, 1).type_as(src).fill_(next_word)\n",
        "        attention_scores.append(model.decoder.attention.alphas.cpu().numpy())\n",
        "    \n",
        "    output = np.array(output)\n",
        "        \n",
        "    # cut off everything starting from </s> \n",
        "    # (only when eos_index provided)\n",
        "    if eos_index is not None:\n",
        "        first_eos = np.where(output==eos_index)[0]\n",
        "        if len(first_eos) > 0:\n",
        "            output = output[:first_eos[0]]      \n",
        "    \n",
        "    return output, np.concatenate(attention_scores, axis=1)\n",
        "  \n",
        "\n",
        "def lookup_words(x, vocab=None):\n",
        "    if vocab is not None:\n",
        "        x = [vocab.itos[i] for i in x]\n",
        "\n",
        "    return [str(t) for t in x]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CuNfvDQIO3xK"
      },
      "source": [
        "def print_examples(example_iter, model, n=2, max_len=100, \n",
        "                   sos_index=1, \n",
        "                   src_eos_index=None, \n",
        "                   trg_eos_index=None, \n",
        "                   src_vocab=None, trg_vocab=None):\n",
        "    \"\"\"Prints N examples. Assumes batch size of 1.\"\"\"\n",
        "\n",
        "    model.eval()\n",
        "    count = 0\n",
        "    print()\n",
        "    \n",
        "    if src_vocab is not None and trg_vocab is not None:\n",
        "        src_eos_index = src_vocab.stoi[EOS_TOKEN]\n",
        "        trg_sos_index = trg_vocab.stoi[SOS_TOKEN]\n",
        "        trg_eos_index = trg_vocab.stoi[EOS_TOKEN]\n",
        "    else:\n",
        "        src_eos_index = None\n",
        "        trg_sos_index = 1\n",
        "        trg_eos_index = None\n",
        "        \n",
        "    for i, batch in enumerate(example_iter):\n",
        "      \n",
        "        src = batch.src.cpu().numpy()[0, :]\n",
        "        trg = batch.trg_y.cpu().numpy()[0, :]\n",
        "\n",
        "        # remove </s> (if it is there)\n",
        "        src = src[:-1] if src[-1] == src_eos_index else src\n",
        "        trg = trg[:-1] if trg[-1] == trg_eos_index else trg      \n",
        "      \n",
        "        result, _ = greedy_decode(\n",
        "          model, batch.src, batch.src_mask, batch.src_lengths,\n",
        "          max_len=max_len, sos_index=trg_sos_index, eos_index=trg_eos_index)\n",
        "        print(\"Example #%d\" % (i+1))\n",
        "        print(\"Src : \", \" \".join(lookup_words(src, vocab=src_vocab)))\n",
        "        print(\"Trg : \", \" \".join(lookup_words(trg, vocab=trg_vocab)))\n",
        "        print(\"Pred: \", \" \".join(lookup_words(result, vocab=trg_vocab)))\n",
        "        print()\n",
        "        \n",
        "        count += 1\n",
        "        if count == n:\n",
        "            break"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpfNoWwAO6XC"
      },
      "source": [
        "def train_copy_task():\n",
        "    \"\"\"Train the simple copy task.\"\"\"\n",
        "    num_words = 11\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=0)\n",
        "    model = make_model(num_words, num_words, emb_size=32, hidden_size=64)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
        "    eval_data = list(data_gen(num_words=num_words, batch_size=1, num_batches=100))\n",
        " \n",
        "    dev_perplexities = []\n",
        "    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    for epoch in range(10):\n",
        "        \n",
        "        print(\"Epoch %d\" % epoch)\n",
        "\n",
        "        # train\n",
        "        model.train()\n",
        "        data = data_gen(num_words=num_words, batch_size=32, num_batches=100)\n",
        "        run_epoch(data, model,\n",
        "                  SimpleLossCompute(model.generator, criterion, optim))\n",
        "\n",
        "        # evaluate\n",
        "        model.eval()\n",
        "        with torch.no_grad(): \n",
        "            perplexity = run_epoch(eval_data, model,\n",
        "                                   SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Evaluation perplexity: %f\" % perplexity)\n",
        "            dev_perplexities.append(perplexity)\n",
        "            print_examples(eval_data, model, n=2, max_len=9)\n",
        "        \n",
        "    return dev_perplexities"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efCFQ88-O9Ki",
        "outputId": "7402d267-59ef-43a8-da41-6aefe4e04c90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# train the copy task\n",
        "dev_perplexities = train_copy_task()\n",
        "\n",
        "def plot_perplexity(perplexities):\n",
        "    \"\"\"plot perplexities\"\"\"\n",
        "    plt.title(\"Perplexity per Epoch\")\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Perplexity\")\n",
        "    plt.plot(perplexities)\n",
        "    \n",
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n",
            "Epoch Step: 50 Loss: 19.720032 Tokens per Sec: 14365.940734\n",
            "Epoch Step: 100 Loss: 17.850552 Tokens per Sec: 14501.471829\n",
            "Evaluation perplexity: 7.165516\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  5 8 7 5 8 7 5 8 7\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 8 8 8 8 8 8 8\n",
            "\n",
            "Epoch 1\n",
            "Epoch Step: 50 Loss: 15.429652 Tokens per Sec: 14405.938498\n",
            "Epoch Step: 100 Loss: 11.758206 Tokens per Sec: 13882.907454\n",
            "Evaluation perplexity: 3.761093\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 5 3 8 7 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 8 2 5 8 3 2\n",
            "\n",
            "Epoch 2\n",
            "Epoch Step: 50 Loss: 9.917423 Tokens per Sec: 14333.691830\n",
            "Epoch Step: 100 Loss: 8.949948 Tokens per Sec: 12929.616986\n",
            "Evaluation perplexity: 2.573576\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 7 8 10\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 8 5 2 6 8 2\n",
            "\n",
            "Epoch 3\n",
            "Epoch Step: 50 Loss: 7.275529 Tokens per Sec: 14083.023978\n",
            "Epoch Step: 100 Loss: 6.582399 Tokens per Sec: 14399.941635\n",
            "Evaluation perplexity: 2.072119\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 8 7 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 2 5 8 2 6\n",
            "\n",
            "Epoch 4\n",
            "Epoch Step: 50 Loss: 5.942050 Tokens per Sec: 14414.048727\n",
            "Epoch Step: 100 Loss: 4.906624 Tokens per Sec: 14757.806897\n",
            "Evaluation perplexity: 1.765160\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 5 10 8 7\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 5\n",
            "Epoch Step: 50 Loss: 5.266299 Tokens per Sec: 13692.857915\n",
            "Epoch Step: 100 Loss: 4.140485 Tokens per Sec: 14674.448985\n",
            "Evaluation perplexity: 1.565405\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 3 10 5 7 8\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 6\n",
            "Epoch Step: 50 Loss: 3.958579 Tokens per Sec: 13939.144274\n",
            "Epoch Step: 100 Loss: 3.681249 Tokens per Sec: 13471.629805\n",
            "Evaluation perplexity: 1.455613\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 5 8 7\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 8 6\n",
            "\n",
            "Epoch 7\n",
            "Epoch Step: 50 Loss: 2.987804 Tokens per Sec: 11324.377326\n",
            "Epoch Step: 100 Loss: 2.790761 Tokens per Sec: 13121.423418\n",
            "Evaluation perplexity: 1.366846\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 8\n",
            "Epoch Step: 50 Loss: 2.148365 Tokens per Sec: 14481.954880\n",
            "Epoch Step: 100 Loss: 2.303624 Tokens per Sec: 13497.104640\n",
            "Evaluation perplexity: 1.275108\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n",
            "Epoch 9\n",
            "Epoch Step: 50 Loss: 2.088930 Tokens per Sec: 14347.253549\n",
            "Epoch Step: 100 Loss: 2.050289 Tokens per Sec: 14164.844821\n",
            "Evaluation perplexity: 1.195517\n",
            "\n",
            "Example #1\n",
            "Src :  4 8 5 7 10 3 7 8 5\n",
            "Trg :  4 8 5 7 10 3 7 8 5\n",
            "Pred:  4 8 5 7 10 3 7 8 5\n",
            "\n",
            "Example #2\n",
            "Src :  8 8 3 6 5 2 8 6 2\n",
            "Trg :  8 8 3 6 5 2 8 6 2\n",
            "Pred:  8 8 3 6 5 2 8 6 2\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUB0-jHTVLDc",
        "outputId": "4309e888-3a7e-4577-cd79-564d5dfa099a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 574
        }
      },
      "source": [
        "!python -m spacy download de_core_news_sm"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting de_core_news_sm==2.2.5\n",
            "\u001b[?25l  Downloading https://github.com/explosion/spacy-models/releases/download/de_core_news_sm-2.2.5/de_core_news_sm-2.2.5.tar.gz (14.9MB)\n",
            "\u001b[K     |████████████████████████████████| 14.9MB 535kB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.6/dist-packages (from de_core_news_sm==2.2.5) (2.2.4)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.3)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (0.4.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.18.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (7.4.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (50.3.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (1.0.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.6/dist-packages (from spacy>=2.2.2->de_core_news_sm==2.2.5) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata>=0.20; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.0.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->de_core_news_sm==2.2.5) (2020.6.20)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=0.20; python_version < \"3.8\"->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->de_core_news_sm==2.2.5) (3.2.0)\n",
            "Building wheels for collected packages: de-core-news-sm\n",
            "  Building wheel for de-core-news-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for de-core-news-sm: filename=de_core_news_sm-2.2.5-cp36-none-any.whl size=14907056 sha256=119b56858cd07a685ac8e07fde02476a24fe4dc911db73f96cb25effe4469992\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qx1r7le3/wheels/ba/3f/ed/d4aa8e45e7191b7f32db4bfad565e7da1edbf05c916ca7a1ca\n",
            "Successfully built de-core-news-sm\n",
            "Installing collected packages: de-core-news-sm\n",
            "Successfully installed de-core-news-sm-2.2.5\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('de_core_news_sm')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HSZmhLrqPEFS",
        "outputId": "96457b9d-fd14-482e-887e-d3ff05a96b94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        }
      },
      "source": [
        "# For data loading.\n",
        "import de_core_news_sm\n",
        "from torchtext import data, datasets\n",
        "import spacy\n",
        "if True:\n",
        "    import spacy\n",
        "    spacy_de = de_core_news_sm.load()\n",
        "    spacy_en = spacy.load('en')\n",
        "\n",
        "    def tokenize_de(text):\n",
        "        return [tok.text for tok in spacy_de.tokenizer(text)]\n",
        "\n",
        "    def tokenize_en(text):\n",
        "        return [tok.text for tok in spacy_en.tokenizer(text)]\n",
        "\n",
        "    UNK_TOKEN = \"<unk>\"\n",
        "    PAD_TOKEN = \"<pad>\"    \n",
        "    SOS_TOKEN = \"<s>\"\n",
        "    EOS_TOKEN = \"</s>\"\n",
        "    LOWER = True\n",
        "    \n",
        "    # we include lengths to provide to the RNNs\n",
        "    SRC = data.Field(tokenize=tokenize_de, \n",
        "                     batch_first=True, lower=LOWER, include_lengths=True,\n",
        "                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=None, eos_token=EOS_TOKEN)\n",
        "    TRG = data.Field(tokenize=tokenize_en, \n",
        "                     batch_first=True, lower=LOWER, include_lengths=True,\n",
        "                     unk_token=UNK_TOKEN, pad_token=PAD_TOKEN, init_token=SOS_TOKEN, eos_token=EOS_TOKEN)\n",
        "\n",
        "    MAX_LEN = 25  # NOTE: we filter out a lot of sentences for speed\n",
        "    train_data, valid_data, test_data = datasets.IWSLT.splits(\n",
        "        exts=('.de', '.en'), fields=(SRC, TRG), \n",
        "        filter_pred=lambda x: len(vars(x)['src']) <= MAX_LEN and \n",
        "            len(vars(x)['trg']) <= MAX_LEN)\n",
        "    MIN_FREQ = 5  # NOTE: we limit the vocabulary to frequent words for speed\n",
        "    SRC.build_vocab(train_data.src, min_freq=MIN_FREQ)\n",
        "    TRG.build_vocab(train_data.trg, min_freq=MIN_FREQ)\n",
        "    \n",
        "    PAD_INDEX = TRG.vocab.stoi[PAD_TOKEN]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading de-en.tgz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "de-en.tgz: 100%|██████████| 24.2M/24.2M [00:08<00:00, 2.77MB/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.dev2012.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2011.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.dev2010.de-en.de.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2013.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TED.tst2014.de-en.en.xml\n",
            ".data/iwslt/de-en/IWSLT16.TEDX.tst2013.de-en.de.xml\n",
            ".data/iwslt/de-en/train.tags.de-en.de\n",
            ".data/iwslt/de-en/train.tags.de-en.en\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jJfr2LhTPG3X",
        "outputId": "d420108b-67cd-41f1-885c-05d5e01a40a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def print_data_info(train_data, valid_data, test_data, src_field, trg_field):\n",
        "    \"\"\" This prints some useful stuff about our data sets. \"\"\"\n",
        "\n",
        "    print(\"Data set sizes (number of sentence pairs):\")\n",
        "    print('train', len(train_data))\n",
        "    print('valid', len(valid_data))\n",
        "    print('test', len(test_data), \"\\n\")\n",
        "\n",
        "    print(\"First training example:\")\n",
        "    print(\"src:\", \" \".join(vars(train_data[0])['src']))\n",
        "    print(\"trg:\", \" \".join(vars(train_data[0])['trg']), \"\\n\")\n",
        "\n",
        "    print(\"Most common words (src):\")\n",
        "    print(\"\\n\".join([\"%10s %10d\" % x for x in src_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
        "    print(\"Most common words (trg):\")\n",
        "    print(\"\\n\".join([\"%10s %10d\" % x for x in trg_field.vocab.freqs.most_common(10)]), \"\\n\")\n",
        "\n",
        "    print(\"First 10 words (src):\")\n",
        "    print(\"\\n\".join(\n",
        "        '%02d %s' % (i, t) for i, t in enumerate(src_field.vocab.itos[:10])), \"\\n\")\n",
        "    print(\"First 10 words (trg):\")\n",
        "    print(\"\\n\".join(\n",
        "        '%02d %s' % (i, t) for i, t in enumerate(trg_field.vocab.itos[:10])), \"\\n\")\n",
        "\n",
        "    print(\"Number of German words (types):\", len(src_field.vocab))\n",
        "    print(\"Number of English words (types):\", len(trg_field.vocab), \"\\n\")\n",
        "    \n",
        "    \n",
        "print_data_info(train_data, valid_data, test_data, SRC, TRG)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data set sizes (number of sentence pairs):\n",
            "train 143115\n",
            "valid 690\n",
            "test 963 \n",
            "\n",
            "First training example:\n",
            "src: david gallo : das ist bill lange . ich bin dave gallo .\n",
            "trg: david gallo : this is bill lange . i 'm dave gallo . \n",
            "\n",
            "Most common words (src):\n",
            "         .     138329\n",
            "         ,     105944\n",
            "       und      41843\n",
            "       die      40808\n",
            "       das      33324\n",
            "       sie      33034\n",
            "       ich      31150\n",
            "       ist      31037\n",
            "        es      27449\n",
            "       wir      25817 \n",
            "\n",
            "Most common words (trg):\n",
            "         .     137259\n",
            "         ,      91615\n",
            "       the      73343\n",
            "       and      50276\n",
            "        to      42799\n",
            "         a      39572\n",
            "        of      39496\n",
            "         i      33521\n",
            "        it      32920\n",
            "      that      32640 \n",
            "\n",
            "First 10 words (src):\n",
            "00 <unk>\n",
            "01 <pad>\n",
            "02 </s>\n",
            "03 .\n",
            "04 ,\n",
            "05 und\n",
            "06 die\n",
            "07 das\n",
            "08 sie\n",
            "09 ich \n",
            "\n",
            "First 10 words (trg):\n",
            "00 <unk>\n",
            "01 <pad>\n",
            "02 <s>\n",
            "03 </s>\n",
            "04 .\n",
            "05 ,\n",
            "06 the\n",
            "07 and\n",
            "08 to\n",
            "09 a \n",
            "\n",
            "Number of German words (types): 15765\n",
            "Number of English words (types): 13002 \n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "798NuxfBPG7h"
      },
      "source": [
        "train_iter = data.BucketIterator(train_data, batch_size=64, train=True, \n",
        "                                 sort_within_batch=True, \n",
        "                                 sort_key=lambda x: (len(x.src), len(x.trg)), repeat=False,\n",
        "                                 device=DEVICE)\n",
        "valid_iter = data.Iterator(valid_data, batch_size=1, train=False, sort=False, repeat=False, \n",
        "                           device=DEVICE)\n",
        "\n",
        "\n",
        "def rebatch(pad_idx, batch):\n",
        "    \"\"\"Wrap torchtext batch into our own Batch class for pre-processing\"\"\"\n",
        "    return Batch(batch.src, batch.trg, pad_idx)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j7ww6K-hPGzq"
      },
      "source": [
        "def train(model, num_epochs=10, lr=0.0003, print_every=100):\n",
        "    \"\"\"Train a model on IWSLT\"\"\"\n",
        "    \n",
        "    if USE_CUDA:\n",
        "        model.cuda()\n",
        "\n",
        "    # optionally add label smoothing; see the Annotated Transformer\n",
        "    criterion = nn.NLLLoss(reduction=\"sum\", ignore_index=PAD_INDEX)\n",
        "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    \n",
        "    dev_perplexities = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "      \n",
        "        print(\"Epoch\", epoch)\n",
        "        model.train()\n",
        "        train_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in train_iter), \n",
        "                                     model,\n",
        "                                     SimpleLossCompute(model.generator, criterion, optim),\n",
        "                                     print_every=print_every)\n",
        "        \n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            print_examples((rebatch(PAD_INDEX, x) for x in valid_iter), \n",
        "                           model, n=3, src_vocab=SRC.vocab, trg_vocab=TRG.vocab)        \n",
        "\n",
        "            dev_perplexity = run_epoch((rebatch(PAD_INDEX, b) for b in valid_iter), \n",
        "                                       model, \n",
        "                                       SimpleLossCompute(model.generator, criterion, None))\n",
        "            print(\"Validation perplexity: %f\" % dev_perplexity)\n",
        "            dev_perplexities.append(dev_perplexity)\n",
        "        \n",
        "    return dev_perplexities\n",
        "        "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "79gTXzt2PPAs",
        "outputId": "fe3f80f5-4b78-4e7d-b173-b206ebf3017e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = make_model(len(SRC.vocab), len(TRG.vocab),\n",
        "                   emb_size=256, hidden_size=256,\n",
        "                   num_layers=1, dropout=0.2)\n",
        "dev_perplexities = train(model, print_every=100)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:50: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch Step: 100 Loss: 52.647751 Tokens per Sec: 21969.002270\n",
            "Epoch Step: 200 Loss: 24.595844 Tokens per Sec: 22816.671457\n",
            "Epoch Step: 300 Loss: 71.748009 Tokens per Sec: 21255.304468\n",
            "Epoch Step: 400 Loss: 55.833321 Tokens per Sec: 23511.126775\n",
            "Epoch Step: 500 Loss: 41.502430 Tokens per Sec: 22064.855431\n",
            "Epoch Step: 600 Loss: 88.420654 Tokens per Sec: 21774.364317\n",
            "Epoch Step: 700 Loss: 44.992691 Tokens per Sec: 22347.807042\n",
            "Epoch Step: 800 Loss: 53.790089 Tokens per Sec: 22513.518114\n",
            "Epoch Step: 900 Loss: 84.505623 Tokens per Sec: 23005.182113\n",
            "Epoch Step: 1000 Loss: 89.647247 Tokens per Sec: 23225.161186\n",
            "Epoch Step: 1100 Loss: 93.354523 Tokens per Sec: 21917.192588\n",
            "Epoch Step: 1200 Loss: 59.013252 Tokens per Sec: 22202.162579\n",
            "Epoch Step: 1300 Loss: 64.903946 Tokens per Sec: 23587.787419\n",
            "Epoch Step: 1400 Loss: 46.600098 Tokens per Sec: 22643.694455\n",
            "Epoch Step: 1500 Loss: 23.304394 Tokens per Sec: 23933.217191\n",
            "Epoch Step: 1600 Loss: 22.210661 Tokens per Sec: 21695.776404\n",
            "Epoch Step: 1700 Loss: 25.541658 Tokens per Sec: 22571.131021\n",
            "Epoch Step: 1800 Loss: 33.560982 Tokens per Sec: 22877.490519\n",
            "Epoch Step: 1900 Loss: 20.306936 Tokens per Sec: 23379.105400\n",
            "Epoch Step: 2000 Loss: 14.941701 Tokens per Sec: 22117.249594\n",
            "Epoch Step: 2100 Loss: 23.149927 Tokens per Sec: 22552.477111\n",
            "Epoch Step: 2200 Loss: 98.963486 Tokens per Sec: 23450.519866\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was years old , i was a <unk> of the <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father is to <unk> , and the <unk> of the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he was very much , what was the only thing that was the <unk> .\n",
            "\n",
            "Validation perplexity: 32.511938\n",
            "Epoch 1\n",
            "Epoch Step: 100 Loss: 24.140959 Tokens per Sec: 20945.230444\n",
            "Epoch Step: 200 Loss: 31.308218 Tokens per Sec: 22681.577650\n",
            "Epoch Step: 300 Loss: 48.616020 Tokens per Sec: 22185.755003\n",
            "Epoch Step: 400 Loss: 54.732494 Tokens per Sec: 21890.370909\n",
            "Epoch Step: 500 Loss: 45.590370 Tokens per Sec: 22684.377472\n",
            "Epoch Step: 600 Loss: 11.021554 Tokens per Sec: 21831.595355\n",
            "Epoch Step: 700 Loss: 87.047539 Tokens per Sec: 23805.831472\n",
            "Epoch Step: 800 Loss: 18.471502 Tokens per Sec: 23870.900174\n",
            "Epoch Step: 900 Loss: 36.261364 Tokens per Sec: 22098.625654\n",
            "Epoch Step: 1000 Loss: 87.779945 Tokens per Sec: 23623.215965\n",
            "Epoch Step: 1100 Loss: 20.057674 Tokens per Sec: 22365.235617\n",
            "Epoch Step: 1200 Loss: 67.045998 Tokens per Sec: 23010.330643\n",
            "Epoch Step: 1300 Loss: 36.661686 Tokens per Sec: 22963.488550\n",
            "Epoch Step: 1400 Loss: 9.572822 Tokens per Sec: 22181.525703\n",
            "Epoch Step: 1500 Loss: 28.356405 Tokens per Sec: 23074.068349\n",
            "Epoch Step: 1600 Loss: 82.746521 Tokens per Sec: 22335.736959\n",
            "Epoch Step: 1700 Loss: 40.467167 Tokens per Sec: 22874.384960\n",
            "Epoch Step: 1800 Loss: 73.220200 Tokens per Sec: 22905.598399\n",
            "Epoch Step: 1900 Loss: 17.815941 Tokens per Sec: 23295.154777\n",
            "Epoch Step: 2000 Loss: 7.987629 Tokens per Sec: 23512.993251\n",
            "Epoch Step: 2100 Loss: 21.788631 Tokens per Sec: 22813.019738\n",
            "Epoch Step: 2200 Loss: 34.373856 Tokens per Sec: 23231.752545\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a ph.d. from the <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little , small <unk> , the <unk> of the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much , there was the news <unk> .\n",
            "\n",
            "Validation perplexity: 19.924691\n",
            "Epoch 2\n",
            "Epoch Step: 100 Loss: 63.584782 Tokens per Sec: 21179.216913\n",
            "Epoch Step: 200 Loss: 26.169092 Tokens per Sec: 23696.431480\n",
            "Epoch Step: 300 Loss: 67.101120 Tokens per Sec: 23050.760239\n",
            "Epoch Step: 400 Loss: 44.900654 Tokens per Sec: 23588.820371\n",
            "Epoch Step: 500 Loss: 31.226719 Tokens per Sec: 23613.679903\n",
            "Epoch Step: 600 Loss: 22.349781 Tokens per Sec: 23351.795727\n",
            "Epoch Step: 700 Loss: 28.740271 Tokens per Sec: 23573.681178\n",
            "Epoch Step: 800 Loss: 40.912796 Tokens per Sec: 22829.100675\n",
            "Epoch Step: 900 Loss: 46.473911 Tokens per Sec: 23069.552970\n",
            "Epoch Step: 1000 Loss: 35.473938 Tokens per Sec: 21973.046372\n",
            "Epoch Step: 1100 Loss: 22.898874 Tokens per Sec: 23295.291745\n",
            "Epoch Step: 1200 Loss: 62.774353 Tokens per Sec: 22789.233356\n",
            "Epoch Step: 1300 Loss: 29.503052 Tokens per Sec: 21274.252758\n",
            "Epoch Step: 1400 Loss: 76.140228 Tokens per Sec: 23547.820209\n",
            "Epoch Step: 1500 Loss: 47.862865 Tokens per Sec: 23073.279978\n",
            "Epoch Step: 1600 Loss: 31.551838 Tokens per Sec: 22400.613171\n",
            "Epoch Step: 1700 Loss: 13.138333 Tokens per Sec: 23455.510953\n",
            "Epoch Step: 1800 Loss: 25.326096 Tokens per Sec: 22571.287877\n",
            "Epoch Step: 1900 Loss: 44.193531 Tokens per Sec: 23186.404475\n",
            "Epoch Step: 2000 Loss: 59.028267 Tokens per Sec: 22740.632551\n",
            "Epoch Step: 2100 Loss: 32.215309 Tokens per Sec: 23110.117329\n",
            "Epoch Step: 2200 Loss: 64.905548 Tokens per Sec: 23263.880019\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was born a <unk> of the <unk> of joy .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my dad was on his little , <unk> , the <unk> of the bbc was the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much , it was the news most <unk> .\n",
            "\n",
            "Validation perplexity: 15.267848\n",
            "Epoch 3\n",
            "Epoch Step: 100 Loss: 30.996975 Tokens per Sec: 22103.908260\n",
            "Epoch Step: 200 Loss: 34.591221 Tokens per Sec: 22063.025145\n",
            "Epoch Step: 300 Loss: 46.230225 Tokens per Sec: 23448.972657\n",
            "Epoch Step: 400 Loss: 70.576248 Tokens per Sec: 23492.007132\n",
            "Epoch Step: 500 Loss: 34.779797 Tokens per Sec: 23745.648796\n",
            "Epoch Step: 600 Loss: 10.889948 Tokens per Sec: 23462.201504\n",
            "Epoch Step: 700 Loss: 64.997406 Tokens per Sec: 22616.273865\n",
            "Epoch Step: 800 Loss: 71.898666 Tokens per Sec: 22668.800268\n",
            "Epoch Step: 900 Loss: 39.440239 Tokens per Sec: 22565.803877\n",
            "Epoch Step: 1000 Loss: 42.698948 Tokens per Sec: 22424.017709\n",
            "Epoch Step: 1100 Loss: 6.460396 Tokens per Sec: 22551.865824\n",
            "Epoch Step: 1200 Loss: 22.674469 Tokens per Sec: 23122.513688\n",
            "Epoch Step: 1300 Loss: 22.695181 Tokens per Sec: 23260.044509\n",
            "Epoch Step: 1400 Loss: 47.420517 Tokens per Sec: 23679.732497\n",
            "Epoch Step: 1500 Loss: 3.655200 Tokens per Sec: 23454.408680\n",
            "Epoch Step: 1600 Loss: 21.391027 Tokens per Sec: 21535.008909\n",
            "Epoch Step: 1700 Loss: 27.410269 Tokens per Sec: 23618.379307\n",
            "Epoch Step: 1800 Loss: 19.652359 Tokens per Sec: 22921.808997\n",
            "Epoch Step: 1900 Loss: 44.726086 Tokens per Sec: 22716.393013\n",
            "Epoch Step: 2000 Loss: 12.223261 Tokens per Sec: 23545.470118\n",
            "Epoch Step: 2100 Loss: 46.146530 Tokens per Sec: 21280.064610\n",
            "Epoch Step: 2200 Loss: 32.294258 Tokens per Sec: 22630.484999\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was born by the morning of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father was on his little bit , little <unk> , the radio <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty much of the time , it was the most powerful job .\n",
            "\n",
            "Validation perplexity: 13.770901\n",
            "Epoch 4\n",
            "Epoch Step: 100 Loss: 26.400103 Tokens per Sec: 21250.393140\n",
            "Epoch Step: 200 Loss: 26.190231 Tokens per Sec: 22053.536039\n",
            "Epoch Step: 300 Loss: 34.641834 Tokens per Sec: 22961.180476\n",
            "Epoch Step: 400 Loss: 64.552124 Tokens per Sec: 22176.434399\n",
            "Epoch Step: 500 Loss: 60.483170 Tokens per Sec: 23025.438868\n",
            "Epoch Step: 600 Loss: 59.313892 Tokens per Sec: 21441.659648\n",
            "Epoch Step: 700 Loss: 12.270987 Tokens per Sec: 22717.797637\n",
            "Epoch Step: 800 Loss: 26.178648 Tokens per Sec: 23207.797328\n",
            "Epoch Step: 900 Loss: 53.893734 Tokens per Sec: 23373.024272\n",
            "Epoch Step: 1000 Loss: 40.260830 Tokens per Sec: 23743.524833\n",
            "Epoch Step: 1100 Loss: 12.783967 Tokens per Sec: 23255.160054\n",
            "Epoch Step: 1200 Loss: 38.077744 Tokens per Sec: 22724.537921\n",
            "Epoch Step: 1300 Loss: 24.481749 Tokens per Sec: 23415.806127\n",
            "Epoch Step: 1400 Loss: 26.192900 Tokens per Sec: 22907.613788\n",
            "Epoch Step: 1500 Loss: 24.950850 Tokens per Sec: 23684.244452\n",
            "Epoch Step: 1600 Loss: 11.974850 Tokens per Sec: 22012.074705\n",
            "Epoch Step: 1700 Loss: 52.857094 Tokens per Sec: 23136.002230\n",
            "Epoch Step: 1800 Loss: 16.638845 Tokens per Sec: 22495.374515\n",
            "Epoch Step: 1900 Loss: 54.202019 Tokens per Sec: 23174.946862\n",
            "Epoch Step: 2000 Loss: 41.912971 Tokens per Sec: 23400.433212\n",
            "Epoch Step: 2100 Loss: 47.144112 Tokens per Sec: 23249.303217\n",
            "Epoch Step: 2200 Loss: 47.831760 Tokens per Sec: 21934.119701\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was born a year from the <unk> of <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my dad listened on his little , tiny radio the bbc was the <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he saw very happy , which was pretty unusual , there was the news most <unk> .\n",
            "\n",
            "Validation perplexity: 12.589193\n",
            "Epoch 5\n",
            "Epoch Step: 100 Loss: 35.079346 Tokens per Sec: 20742.240408\n",
            "Epoch Step: 200 Loss: 19.232189 Tokens per Sec: 22926.607113\n",
            "Epoch Step: 300 Loss: 46.953995 Tokens per Sec: 23482.126814\n",
            "Epoch Step: 400 Loss: 42.777687 Tokens per Sec: 23073.507265\n",
            "Epoch Step: 500 Loss: 47.680462 Tokens per Sec: 22818.857055\n",
            "Epoch Step: 600 Loss: 49.927082 Tokens per Sec: 23474.146777\n",
            "Epoch Step: 700 Loss: 23.856218 Tokens per Sec: 22757.618266\n",
            "Epoch Step: 800 Loss: 25.340460 Tokens per Sec: 22883.515212\n",
            "Epoch Step: 900 Loss: 15.172826 Tokens per Sec: 21672.413686\n",
            "Epoch Step: 1000 Loss: 48.529541 Tokens per Sec: 23782.103304\n",
            "Epoch Step: 1100 Loss: 32.607510 Tokens per Sec: 23408.858702\n",
            "Epoch Step: 1200 Loss: 26.800018 Tokens per Sec: 22293.481772\n",
            "Epoch Step: 1300 Loss: 43.086407 Tokens per Sec: 22805.864207\n",
            "Epoch Step: 1400 Loss: 41.614529 Tokens per Sec: 23653.222925\n",
            "Epoch Step: 1500 Loss: 18.990482 Tokens per Sec: 21449.495167\n",
            "Epoch Step: 1600 Loss: 27.625938 Tokens per Sec: 22552.465141\n",
            "Epoch Step: 1700 Loss: 58.427540 Tokens per Sec: 23565.239499\n",
            "Epoch Step: 1800 Loss: 33.431480 Tokens per Sec: 21763.018990\n",
            "Epoch Step: 1900 Loss: 23.136614 Tokens per Sec: 22054.608963\n",
            "Epoch Step: 2000 Loss: 30.901276 Tokens per Sec: 21755.628235\n",
            "Epoch Step: 2100 Loss: 42.959564 Tokens per Sec: 22933.256349\n",
            "Epoch Step: 2200 Loss: 25.593576 Tokens per Sec: 22877.009056\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was a <unk> of the <unk> of pleasure .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father heard on his little , the radio <unk> came out of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was pretty unusual , and it 's been <unk> in the <unk> , the news most <unk> .\n",
            "\n",
            "Validation perplexity: 12.181488\n",
            "Epoch 6\n",
            "Epoch Step: 100 Loss: 23.572754 Tokens per Sec: 21660.103679\n",
            "Epoch Step: 200 Loss: 47.506268 Tokens per Sec: 22495.058969\n",
            "Epoch Step: 300 Loss: 27.577526 Tokens per Sec: 23087.623146\n",
            "Epoch Step: 400 Loss: 17.649927 Tokens per Sec: 22940.824214\n",
            "Epoch Step: 500 Loss: 25.410500 Tokens per Sec: 22629.686221\n",
            "Epoch Step: 600 Loss: 15.640968 Tokens per Sec: 22607.637454\n",
            "Epoch Step: 700 Loss: 40.981068 Tokens per Sec: 23460.991142\n",
            "Epoch Step: 800 Loss: 24.299438 Tokens per Sec: 23078.421649\n",
            "Epoch Step: 900 Loss: 29.523542 Tokens per Sec: 22906.800793\n",
            "Epoch Step: 1000 Loss: 53.607277 Tokens per Sec: 22467.754278\n",
            "Epoch Step: 1100 Loss: 32.104733 Tokens per Sec: 22440.252595\n",
            "Epoch Step: 1200 Loss: 24.754147 Tokens per Sec: 22336.739522\n",
            "Epoch Step: 1300 Loss: 23.000401 Tokens per Sec: 22479.079927\n",
            "Epoch Step: 1400 Loss: 32.152050 Tokens per Sec: 22578.943758\n",
            "Epoch Step: 1500 Loss: 25.541445 Tokens per Sec: 22243.305891\n",
            "Epoch Step: 1600 Loss: 34.994034 Tokens per Sec: 22799.237053\n",
            "Epoch Step: 1700 Loss: 46.675255 Tokens per Sec: 23034.609124\n",
            "Epoch Step: 1800 Loss: 63.665543 Tokens per Sec: 22801.073214\n",
            "Epoch Step: 1900 Loss: 19.040424 Tokens per Sec: 22603.165615\n",
            "Epoch Step: 2000 Loss: 33.561260 Tokens per Sec: 23047.274273\n",
            "Epoch Step: 2100 Loss: 39.501461 Tokens per Sec: 23387.232087\n",
            "Epoch Step: 2200 Loss: 38.048637 Tokens per Sec: 22717.224021\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was made a <unk> from the <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father heard on his little , the radio <unk> came up the <unk> .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was pretty unusual , because it was the most exciting <unk> .\n",
            "\n",
            "Validation perplexity: 11.642737\n",
            "Epoch 7\n",
            "Epoch Step: 100 Loss: 7.100498 Tokens per Sec: 20764.758877\n",
            "Epoch Step: 200 Loss: 27.563959 Tokens per Sec: 23064.472065\n",
            "Epoch Step: 300 Loss: 45.651176 Tokens per Sec: 23334.000933\n",
            "Epoch Step: 400 Loss: 20.633562 Tokens per Sec: 22271.383085\n",
            "Epoch Step: 500 Loss: 40.970196 Tokens per Sec: 23469.666062\n",
            "Epoch Step: 600 Loss: 47.493015 Tokens per Sec: 22065.886974\n",
            "Epoch Step: 700 Loss: 29.141010 Tokens per Sec: 23455.015328\n",
            "Epoch Step: 800 Loss: 19.948885 Tokens per Sec: 22852.357306\n",
            "Epoch Step: 900 Loss: 39.601387 Tokens per Sec: 21539.122870\n",
            "Epoch Step: 1000 Loss: 8.317408 Tokens per Sec: 22817.730932\n",
            "Epoch Step: 1100 Loss: 37.170410 Tokens per Sec: 22479.735819\n",
            "Epoch Step: 1200 Loss: 40.443192 Tokens per Sec: 23246.638315\n",
            "Epoch Step: 1300 Loss: 46.514954 Tokens per Sec: 23116.494625\n",
            "Epoch Step: 1400 Loss: 5.636326 Tokens per Sec: 21826.018883\n",
            "Epoch Step: 1500 Loss: 21.424871 Tokens per Sec: 22663.726916\n",
            "Epoch Step: 1600 Loss: 43.371006 Tokens per Sec: 22799.421129\n",
            "Epoch Step: 1700 Loss: 46.774139 Tokens per Sec: 23500.761708\n",
            "Epoch Step: 1800 Loss: 8.036802 Tokens per Sec: 21787.671891\n",
            "Epoch Step: 1900 Loss: 22.919636 Tokens per Sec: 22329.173985\n",
            "Epoch Step: 2000 Loss: 41.931034 Tokens per Sec: 23460.281076\n",
            "Epoch Step: 2100 Loss: 56.896790 Tokens per Sec: 22668.160162\n",
            "Epoch Step: 2200 Loss: 54.176151 Tokens per Sec: 23724.661413\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 11 , i was prosecuted by the morning of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my dad listened to his little , the radio shack came out of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was pretty unusual , because it was the most <unk> <unk> .\n",
            "\n",
            "Validation perplexity: 11.636893\n",
            "Epoch 8\n",
            "Epoch Step: 100 Loss: 15.864367 Tokens per Sec: 21902.781128\n",
            "Epoch Step: 200 Loss: 19.993616 Tokens per Sec: 23205.453806\n",
            "Epoch Step: 300 Loss: 43.530796 Tokens per Sec: 22883.681066\n",
            "Epoch Step: 400 Loss: 24.292397 Tokens per Sec: 22291.797235\n",
            "Epoch Step: 500 Loss: 47.898014 Tokens per Sec: 22627.338805\n",
            "Epoch Step: 600 Loss: 20.701347 Tokens per Sec: 22256.271589\n",
            "Epoch Step: 700 Loss: 53.428638 Tokens per Sec: 22573.940386\n",
            "Epoch Step: 800 Loss: 42.013145 Tokens per Sec: 23084.655664\n",
            "Epoch Step: 900 Loss: 11.141827 Tokens per Sec: 21776.602686\n",
            "Epoch Step: 1000 Loss: 20.508762 Tokens per Sec: 22862.195048\n",
            "Epoch Step: 1100 Loss: 20.404779 Tokens per Sec: 22505.210507\n",
            "Epoch Step: 1200 Loss: 42.152954 Tokens per Sec: 22475.088362\n",
            "Epoch Step: 1300 Loss: 22.518627 Tokens per Sec: 22613.550242\n",
            "Epoch Step: 1400 Loss: 34.545502 Tokens per Sec: 22171.176845\n",
            "Epoch Step: 1500 Loss: 8.631424 Tokens per Sec: 22676.143673\n",
            "Epoch Step: 1600 Loss: 18.845829 Tokens per Sec: 22835.250172\n",
            "Epoch Step: 1700 Loss: 39.310047 Tokens per Sec: 23221.259053\n",
            "Epoch Step: 1800 Loss: 25.883060 Tokens per Sec: 21657.841363\n",
            "Epoch Step: 1900 Loss: 37.099400 Tokens per Sec: 22977.493733\n",
            "Epoch Step: 2000 Loss: 43.064915 Tokens per Sec: 22054.884396\n",
            "Epoch Step: 2100 Loss: 11.996965 Tokens per Sec: 23030.965274\n",
            "Epoch Step: 2200 Loss: 34.680981 Tokens per Sec: 23095.454336\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was sent to a morning from the <unk> of the <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my dad listened to his little , the radio <unk> of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was pretty unusual , because the news was <unk> .\n",
            "\n",
            "Validation perplexity: 11.844696\n",
            "Epoch 9\n",
            "Epoch Step: 100 Loss: 8.827383 Tokens per Sec: 21111.931807\n",
            "Epoch Step: 200 Loss: 25.066536 Tokens per Sec: 23182.579630\n",
            "Epoch Step: 300 Loss: 18.738615 Tokens per Sec: 23244.872964\n",
            "Epoch Step: 400 Loss: 24.313837 Tokens per Sec: 23552.836245\n",
            "Epoch Step: 500 Loss: 33.318169 Tokens per Sec: 22213.469002\n",
            "Epoch Step: 600 Loss: 10.914494 Tokens per Sec: 22189.197496\n",
            "Epoch Step: 700 Loss: 21.981829 Tokens per Sec: 23435.013324\n",
            "Epoch Step: 800 Loss: 9.769000 Tokens per Sec: 22666.891516\n",
            "Epoch Step: 900 Loss: 16.142893 Tokens per Sec: 23497.313077\n",
            "Epoch Step: 1000 Loss: 33.645233 Tokens per Sec: 23311.352031\n",
            "Epoch Step: 1100 Loss: 8.877417 Tokens per Sec: 22990.353025\n",
            "Epoch Step: 1200 Loss: 32.187244 Tokens per Sec: 22851.939510\n",
            "Epoch Step: 1300 Loss: 35.026787 Tokens per Sec: 22884.983319\n",
            "Epoch Step: 1400 Loss: 10.133214 Tokens per Sec: 22286.790890\n",
            "Epoch Step: 1500 Loss: 48.676750 Tokens per Sec: 22698.418289\n",
            "Epoch Step: 1600 Loss: 22.201593 Tokens per Sec: 22660.690013\n",
            "Epoch Step: 1700 Loss: 44.839390 Tokens per Sec: 21597.303917\n",
            "Epoch Step: 1800 Loss: 43.888390 Tokens per Sec: 23846.456508\n",
            "Epoch Step: 1900 Loss: 34.828163 Tokens per Sec: 22426.245213\n",
            "Epoch Step: 2000 Loss: 53.095940 Tokens per Sec: 21982.578125\n",
            "Epoch Step: 2100 Loss: 16.973749 Tokens per Sec: 23095.296467\n",
            "Epoch Step: 2200 Loss: 5.060617 Tokens per Sec: 22227.895510\n",
            "\n",
            "Example #1\n",
            "Src :  als ich 11 jahre alt war , wurde ich eines morgens von den <unk> heller freude geweckt .\n",
            "Trg :  when i was 11 , i remember waking up one morning to the sound of joy in my house .\n",
            "Pred:  when i was 11 years old , i was published in a morning by the <unk> of <unk> <unk> .\n",
            "\n",
            "Example #2\n",
            "Src :  mein vater hörte sich auf seinem kleinen , grauen radio die <unk> der bbc an .\n",
            "Trg :  my father was listening to bbc news on his small , gray radio .\n",
            "Pred:  my father heard on his little , the radio shack came to the bbc of the bbc .\n",
            "\n",
            "Example #3\n",
            "Src :  er sah sehr glücklich aus , was damals ziemlich ungewöhnlich war , da ihn die nachrichten meistens <unk> .\n",
            "Trg :  there was a big smile on his face which was unusual then , because the news mostly depressed him .\n",
            "Pred:  he looked very happy , which was really unusual in the time , because it was the most wonderful <unk> .\n",
            "\n",
            "Validation perplexity: 11.800080\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g3KY_iy6PTVL",
        "outputId": "e3c9cdb6-82b5-4396-8426-1323e5a65adc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "plot_perplexity(dev_perplexities)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mV7l38hqgLrz",
        "outputId": "27ea2129-b511-4332-deab-f74ed0a0dd4d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "!pip install sacrebleu"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/c4/8e948f601a4f9609e8b2b58f31966cb13cf17b940b82aa3e767f01c42c52/sacrebleu-1.4.14-py3-none-any.whl (64kB)\n",
            "\r\u001b[K     |█████                           | 10kB 23.1MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 20kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 30kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 40kB 4.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 51kB 3.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 61kB 4.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 3.5MB/s \n",
            "\u001b[?25hCollecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/89/a6/3814b7107e0788040870e8825eebf214d72166adf656ba7d4bf14759a06a/portalocker-2.0.0-py2.py3-none-any.whl\n",
            "Installing collected packages: portalocker, sacrebleu\n",
            "Successfully installed portalocker-2.0.0 sacrebleu-1.4.14\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOm-UOUFPZy7"
      },
      "source": [
        "import sacrebleu"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kul8TaNHPboy",
        "outputId": "ef6b3743-1601-4e6c-afc1-68ab0882a556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# this should result in a perfect BLEU of 100%\n",
        "hypotheses = [\"this is a test\"]\n",
        "references = [\"this is a test\"]\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100.00000000000004\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nonzt-kAPdjO",
        "outputId": "ff3d900c-dbc2-4c9c-8320-d80da2f79ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# here the BLEU score will be lower, because some n-grams won't match\n",
        "hypotheses = [\"this is a test\"]\n",
        "references = [\"this is a fest\"]\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "22.360679774997894\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hFImkZ7YPffy",
        "outputId": "7a9ad391-ec0f-4476-aff1-937a8518e46e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(valid_data)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "690"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhadgj3lPhQL",
        "outputId": "44720446-3388-4cc6-93ba-51c07fe40213",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "references = [\" \".join(example.trg) for example in valid_data]\n",
        "print(len(references))\n",
        "print(references[0])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "690\n",
            "when i was 11 , i remember waking up one morning to the sound of joy in my house .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Bpbjvm3Pjdu",
        "outputId": "df7a1c9f-8843-47c7-99e0-73fa36ffb9e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "references[-2]"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"i 'm always the one taking the picture .\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kv9KgYpFPlh-"
      },
      "source": [
        "hypotheses = []\n",
        "alphas = []  # save the last attention scores\n",
        "for batch in valid_iter:\n",
        "  batch = rebatch(PAD_INDEX, batch)\n",
        "  pred, attention = greedy_decode(\n",
        "    model, batch.src, batch.src_mask, batch.src_lengths, max_len=25,\n",
        "    sos_index=TRG.vocab.stoi[SOS_TOKEN],\n",
        "    eos_index=TRG.vocab.stoi[EOS_TOKEN])\n",
        "  hypotheses.append(pred)\n",
        "  alphas.append(attention)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29na8Q5GPoCS",
        "outputId": "5ad6bfcd-6a72-4931-bfb2-54604acc65ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "hypotheses[0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  70,   11,   24, 1460,  103,  217,    5,   11,   24, 1413,   16,\n",
              "          9,  690,   69,    6,    0,   10,    0,    0,    4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DglD_m5EPp_D",
        "outputId": "91383894-3469-42b7-c0cb-28dfb4a41110",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "hypotheses = [lookup_words(x, TRG.vocab) for x in hypotheses]\n",
        "hypotheses[0]"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['when',\n",
              " 'i',\n",
              " 'was',\n",
              " '11',\n",
              " 'years',\n",
              " 'old',\n",
              " ',',\n",
              " 'i',\n",
              " 'was',\n",
              " 'published',\n",
              " 'in',\n",
              " 'a',\n",
              " 'morning',\n",
              " 'by',\n",
              " 'the',\n",
              " '<unk>',\n",
              " 'of',\n",
              " '<unk>',\n",
              " '<unk>',\n",
              " '.']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCqBViwrPrre",
        "outputId": "9496a62a-36cb-4315-def4-69260fcae638",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# finally, the SacreBLEU raw scorer requires string input, so we convert the lists to strings\n",
        "hypotheses = [\" \".join(x) for x in hypotheses]\n",
        "print(len(hypotheses))\n",
        "print(hypotheses[0])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "690\n",
            "when i was 11 years old , i was published in a morning by the <unk> of <unk> <unk> .\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKFXfkvaPtUw",
        "outputId": "8648fbe3-17a9-43d5-b643-eb83f5ec69f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# now we can compute the BLEU score!\n",
        "bleu = sacrebleu.raw_corpus_bleu(hypotheses, [references], .01).score\n",
        "print(bleu)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24.06706159637014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4GDDi-aPvnU"
      },
      "source": [
        "def plot_heatmap(src, trg, scores):\n",
        "\n",
        "    fig, ax = plt.subplots()\n",
        "    heatmap = ax.pcolor(scores, cmap='viridis')\n",
        "\n",
        "    ax.set_xticklabels(trg, minor=False, rotation='vertical')\n",
        "    ax.set_yticklabels(src, minor=False)\n",
        "\n",
        "    # put the major ticks at the middle of each cell\n",
        "    # and the x-ticks on top\n",
        "    ax.xaxis.tick_top()\n",
        "    ax.set_xticks(np.arange(scores.shape[1]) + 0.5, minor=False)\n",
        "    ax.set_yticks(np.arange(scores.shape[0]) + 0.5, minor=False)\n",
        "    ax.invert_yaxis()\n",
        "\n",
        "    plt.colorbar(heatmap)\n",
        "    plt.show()"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDPWGGsIPx3u",
        "outputId": "82f8e779-04ed-4ae6-813f-e39f74bae492",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        }
      },
      "source": [
        "# This plots a chosen sentence, for which we saved the attention scores above.\n",
        "idx = 5\n",
        "src = valid_data[idx].src + [\"</s>\"]\n",
        "trg = valid_data[idx].trg + [\"</s>\"]\n",
        "pred = hypotheses[idx].split() + [\"</s>\"]\n",
        "pred_att = alphas[idx][0].T[:, :len(pred)]\n",
        "print(\"src\", src)\n",
        "print(\"ref\", trg)\n",
        "print(\"pred\", pred)\n",
        "plot_heatmap(src, pred, pred_att)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "src ['\"', 'jetzt', 'kannst', 'du', 'auf', 'eine', 'richtige', 'schule', 'gehen', ',', '\"', 'sagte', 'er', '.', '</s>']\n",
            "ref ['\"', 'you', 'can', 'go', 'to', 'a', 'real', 'school', 'now', ',', '\"', 'he', 'said', '.', '</s>']\n",
            "pred ['\"', 'now', 'you', 'can', 'go', 'to', 'a', 'long', 'school', ',', '\"', 'he', 'said', '.', '</s>']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXkAAAEOCAYAAABsJGdEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5xdVX338c83wyVAuAooAnJ7goACQROoF1C8IApCFRRU2tJqKVbEarEPtpQqrUXA2ofH0j5Eq1BtBUXUqJGgAlpvkEDCJUGUgkhQkXCTa0hmvs8few85GSZzzpmzZ/bOme/79dqvnL3PPr+9ZnJmnXXWXuu3ZJuIiOhP0+ouQERETJxU8hERfSyVfEREH0slHxHRx1LJR0T0sVTyERF9LJV8REQfSyUfEdHHNqi7ABFNJWmbsZ63/cBklSVivJQZrxGjk3QnYECjPG3bu09ykSK6lko+IqKPpbsmogOSjgIOKXevsf2NOssT0am05CPakPQxYA7wn+WhtwELbf91faWK6Ewq+Yg2JN0EzLI9VO4PAItt71dvySLayxDKiM5s1fJ4y9pKEdGl9MlHtHc2sFjS1RQjbQ4BTq+3SDEWSc8B7nW6KtJdE9EJSTtQ9MsDXGf7N3WWJ9ZN0tbAPcDbbH+t7vLULd01EZ2ZQ9GCP4Q1lX000zuAbwPvqrsgTZBKPqKNcnTN+4Bl5XaqpH+st1Qxhj8GTgF2Lr+BTWnprumSpOm2n6y7HNGepK9TzFht9TCwCLiw0//HjK5Zf0iaDXzU9uskfQDY2PbZdZerTrnx2r1bJN0L/He5/cD2wzWXKUZ3B7Ad8IVy/zjgEWBP4FPAH3QRaytgOFfNlB9ds44P0KfZPmoSi9PqncC/l48/B3yP4sb5lJVKvku2/5ek5wEHA0cAF0h6yPasmosWz/RS263951+XtND2HElLu4iT0TXP9PHy3zcDzwE+X+6/Dbi3jgJJ2hQ4HDgVwPZ9km6T9Erb19RRpiZId02XJO1EUcG/AtifonX3g26+Ekr6w9GO2/6PcZRnAHg2LR/Ytn/ZbZx+JOlW4HXDv4/yw3mB7b0lLbZ9QBexMrpmFJIW2Z7d7tgklWVDYGvbv205tgWA7d9NdnmaIi357v0SWAj8o+2TxxmjtXU5HXg1cAPQVSUv6b3A31G0nIbKwwbSV1z4S+AHkv6HogW+G/DnkjYDLu4y1jRgBcXfzJ6S9rT9/UpLu37aTNLutu8AkLQbsFkdBbG9StJjkqbZHpK0J7AX8K06ytMUacl3SdL+wMspvrI/D/g58D3b/z7mC8eOuRVwie3Du3zd7cBBtu8f77X7naSNKf7QAW4bz01zSedQ9OcvpeXDtMZ+58aQdDgwl+L+h4BdgD+zvaCm8lxP8U17a+CHFA2yp2y/o47yNEEq+XGQNIOioj8YOAHA9i49xNsQuMX287t83dXAa22vHu+1+52klwK7snZ3VrffmG4D9rO9strS9YcRH6Q/rfP3JOkG2y8qv+VuYvtcSUum8j2zdNd0SdIiYGPgRxSjaw6xfVeXMVpHJgwAewNfHEdx7gCukfRN4Ok/LNufGEesviPpc8AewBJgsDxsuuwWo/g9b0jL73iqk/Qq21dJevOIp/aQhO3LaykYSNJLKCZEvbM8NlBTWRohlXz3Xm/7vh5jfLzl8WrgLtvLxxHnl+W2UbnF2mYD+4w3f4mkT1J8KDwOLJH0Xdb+MD21klKun14BXAW8cZTnDNRVyf8F8CHgK7aXStoduLqmsjRCumu6JGlLipudwwtIfA84q9ux8pKezdqjNX471vkTqfyZPkzR/QTj/JmaRtKXgFNt/3qcr/+jsZ633e3N20Ypb0z+G/Bs2y+UtB9wlO1/qLloXZP0IeAK24vrLkvTpJLvkqQvA7ewZnTGHwD72x75tXWsGG8FzgOuobhZdTDwQduXdVmW7YC/Al5AMUoHANuv6jJOzz9TE5X3LGYB17F2C7yrG6blaJwnbQ+W+wMUMykfr7C4k07S94APUsz+PaA8dovtF3YZ5wie+R48q8qydlCG44DXUwxrvpFiRM2Vth+czHI0UbprureH7WNa9j8iaUmXMf4GmDPcei8r6+8AXVXyFCsVXQocCZwM/BEwnq6kKn4moFnfUCi+nVThu8BrgEfL/U2AK4GXVhS/Lpvavk5aa53yrm7iS/p/wKbAocCngWMpPlQnle1LKf4WkHQAxaSoy8sP5O9QtPInvVxNkARl3XtC0suHdyS9DHiiyxjTRlR+9zO+/4tnlUM3V9n+nu0/AbpqxZeq+JmGv6FcB7wFeCtwraRjx1GeStj+HvBTYPNyu7U81q3ptocreMrHm1ZTylqtkLQH5SCA8v+q266tl9r+Q+BB2x8BXkKRNqI2thfbPtv2oRQNoKVM4YyUacl3793AxWU/NsCDFC3obnxL0gLWzqkyfxxlWVX+++vyK/OvgG3GEedk4D96/Jmgum8olRilW+yTkrruFgMek/Qi2zeUcWczjg/BBnoPxRj3vSTdA9xJMSqlG8PzDh6X9FyKGeC1ZH4s0xrMtH1jy+GtgJ/Y/nIdZWqCVPLduxU4l2Jo3lYUWQ1/H7ipixjLgR+z5kbnXNtfGUdZ/qGsmP8S+CSwBcXogm69mqI/fka5/ygwp5w52E23TVXfUIYXfpjJ2v283c4wrepD533AlyT9qtzfgeKDeX13D/BZitEn2wC/o/hw76Y//evlZL7zKGZtmyL5Wx1WUXTR7Gf7sfLYp4G/pvhZp6RU8t37GvAQxRt6vG+c7SmSKN0AfAYY7+zAt1DkzbkFOFTSNhTDM7/eZZzZ5TaPosX7DooPrZMlfcn2uR3GqeQbiqR3UVSsO1GMcf89ig/FbruiqvrQ2Q04gGKG85uBgxgjA+N6pPW9/Ks2567LT4FB21+WtA/wIuCrFZWvK2Vag69QdBV+tsxVtJ3tRXWUpzFsZ+tio5iZWkUcAa8DLgFuB/6R4gZoNzEWd3KsgzjfB2a07M+gGEa5CbCsizjnUFSCnyi3NwHnjKM8N1O04JeU+3sBl48jznkUH6Anltu3xlmem8p/X07R6j0CuLbu92IF78Ge38tN+92U75Xvl4/PoBhCW/vvus5tStx4lXS1pKskVdE3/CNJ+/YaxMW78Dfltpoi18ZlkjptNQNMK7s1AChb8uP5drY9a8/mXEUxdvoJupvl+Vrbl9v+QLl9hWJYW7eedJljRtLGtn8KdJXyAcD2Byn6nPcrt7m2//c4yjM8W/YI4FO2v0kFk88k7VCmBOjmNU17L0/I72a8yveKyjkAx1PklJ/Spkp3zYkUX68H25zXiZcDJ0q6k6ICFEWd3XHmR0nvA/6QIqvhpynGyK+SNI0i4dlfdRjqn4Afl5N+oOi++Win5WjxnxQjYYYXPX4j8F/l+PBl7V4s6d3AnwO7q1hFadjmFEmiurW87Of9KvBtSQ8CXaWOGObihluvN93ukXQh8FrgnLJirqKB9DmKNABftn1ah685kR7fy5JuLmNsAPyxpDsY53uZifvdDJf1Oe4+rfO/U/xd3eyMk58ak6HKCtnAfbYP6jHWqInI3EX+GkkfAT4z2msk7W371i5i7cOavuqrbLetlNcRZzbwsnL3h+6iH7O8+bs1xeIarYtpPGL7gdFf1XHsV1CsxHSF7ac6fM0jjN5nPlyJbdFlGYYXo7jZ9s9V5Jbf1/aV3cRZR2xRpF7oaBGTKt7L63oPD+vyvTxhv5sy/jdtH9HlazalGAp6jO3vVFGO9dmUqOQjIqaqKdEnHxExVU3JSl7SSYmzfsRpUlkSZ3LiNKks/WBKVvJAVf/5iTPxcZpUlsSZnDhNKst6b6pW8hERU0Lf3XjdcpsN/OwdNxzznIcfWM2W24w9evSuh7dte63BRx9jYMbYaxZvfPdjYz4PsIqVbEhXw6WnTJwmlSVxJifOZJblER5cYXu7Xq7zukM38/0PdDai9fqbVi5wl2s596rvxsk/e8cN+eS83XqOc/I339n+pA7MfP/CnmN4qKIPYg+1PydiCvmOLxvX/ItW9z8wyHULntfRuQM7/Lx967FifVfJR0RMJgNDNLcBlUo+IqIHxqxyFZPpJ0Yq+YiIHjW5Jb/ejK6R9AtJu0q6pu6yREQMM2bQnW11SEs+IqJHQw1eXmB9quTvo8i811PCq4iIKhUpQVPJ98z2nPLhm0c+V05fPglg++euNz9SRPSJtOQnmO25FItDsOe+mzT3tx0RfcfAqgZPKu2LSj4ioi7G6a6JiOhbhsHm1vGp5CMielHMeG2u9WacfEREM4nBDre2kaTDJd0m6XZJp4/y/D9LWlJuP5P0ULuYfdeSv/f2rfjnI9/Uc5wtD63m82/wZd2siTy6DR5eWUFJQP/zy0riDD3xRCVxPNjcqeB1m7bRRpXEGXqqo2VxowfFjdf2FXg7kgaACygWRV8OLJQ0r3XdZtvvbzn/vcAB7eKmJR8R0YNinHwlLfkDgdtt31EuWn8JcPQY578N+EK7oH3Xko+ImGxDnbfkt5W0qGV/bjkEHGBH4O6W55YDB40WRNIuwG7AVe0umEo+IqIHwy35Dq2wPbuCyx4PXGa3T3+ZSj4iogdGDFbT830PsHPL/k7lsdEcD7ynk6CT0icv6UdjPLeVpD9v8/q250RE1GXI6mhrYyEwU9JukjaiqMjnjTxJ0l7A1sCPOynbpFTytl86xtNbAe0q8E7OiYiYdEY85YGOtjHj2KuBU4AFwK3AF20vlXSWpKNaTj0euMQdLtA9Kd01kh61PUPSB4G3AhsDX7H9d8DHgD0kLQG+DTwBDP9A2wFXApu0nmP7g5NR7oiIdorJUNW0l23PB+aPOHbmiP0PdxNz0vrkJR0GzKQYJiRgnqRDgNOBF9qe1XL6mZK2Av4b+Bfg/lHOaY39dBbK6RtuMXE/RETEKLq48TrpJvPG62Hltrjcn0FR6T9jho4kAZ8HPmH7ekm7jhW4NQvllpvs0OAsEhHRb2wx6OZOOZrMSl7A2bYvXOvg6BX4h4Hltj878cWKiOjNUFryQHEz4e8l/aftRyXtCKwCHgE2Hz5J0huB1wCHtrx2rXMiIpqiuPHa3NHok1Uy275S0t7Aj4veGB4FTrD9P5J+KOkW4FvAbIqZX9eV582zfWbrObnxGhFNUeWN14kw4ZW8pGdRrstq+3zg/JHn2H57uzidnBMRUYfBChKUTZQJreQlPRe4Bvj4RF4nIqIuFc54nRATWsnb/hWw50Re4xnX3GCAVdvP6DnO0IYVFAb4q89+vucYf3vb71dQEtjm7dX8dydF8MRLiuD1y1BG10RE9KciQVkq+YiIvmTEqjYpC+qUSj4iogc2jZ4MNa6SSdq1HM44aSTNkvSGybxmRER7YqjDrQ7rU0t+FsUY+vntToyImCymD1vyrSTtLmmxpIMk/bh8/CNJzy+fP1HS5ZKukPRzSee2vPZRSR+VdKOkn0h6dnn8LZJuKY9/v8ytfBZwXLlK+XG9ljsioiqDTOtoq0NPVy0r8i8DJ1LkPz7Y9gHAmcA/tpw6CzgO2Jeioh5e/WQz4Ce29we+D/xpefxM4HXl8aPKRW3PBC61Pcv2pb2UOyKiKqazBUO6WAe2Ur1012wHfA14s+1lZcV9saSZFN9gWkeaf9f2wwCSlgG7UCxY+xTwjfKc64HXlo9/CFwk6YvA5e0K0ppqeOONt+rhR4qI6I6BVQ3OXdNLS/5hijTBLy/3/x642vYLgTcC01vOXdnyeJA1Hy6rWlY3efq47ZOBMyjWO7y+TI2wTrbn2p5te/ZGG27Ww48UEdEtMdjhVodePn6eAt4ELJD0KLAlaxadPbGXQknaw/a1wLWSXk9R2ScTZUQ0jmn2jNeeSmb7MeBI4P3AEuBsSYvpfdTOeZJuLodp/gi4Ebga2Cc3XiOiafquJW/7F8ALy8cPAXPKpz7SctoZ5fMXARe1vPbIlsczWh5fBlxWPn7zKJd9oOU6ERGNYKt/W/IREVNdceN1oKOtHUmHS7pN0u2STl/HOW+VtEzSUkn/1S5mc28Jj5Mee4INftz7ZNzn3rhpBaWB//P1I3qOsdnuW1ZQEvDK5ZXEmbbx9PYndWBo5ZOVxOlLqqj95aFq4sQYqlnjVdIAcAHFKMPlwEJJ82wvazlnJvAh4GW2H5S0fbu4aclHRPSguPFayTj5A4Hbbd9Rzg26BDh6xDl/Clxg+0EA279tFzSVfEREj7qY8bqtpEUt20ktYXakmD80bHl5rNWewJ7lcqg/kXR4u7L1XXdNRMRkGp7x2qEVtmf3cLkNgJnAK4GdgO9L2rccALPOF0RERA8qWsj7Hoo5QcN2Ys3co2HLgWttrwLulPQzikp/4bqCNrK7RtKHJZ1WdzkiItqxYdXQtI62NhYCMyXtViZlPB6YN+Kcr1K04pG0LUX3zR1jBU1LPiKiB0V3Te/tZdurJZ0CLAAGgM/YXirpLGCR7Xnlc4eVOcAGgQ/avn+suI2p5CX9DfBHwG8pbj5cL+ka4DTbi8pPrUW2d62vlBERz1TVbFbb8xmxZobtM1seG/hAuXWkEZW8pBdTfDWZRVGmGyiyUnb6+qezUE6nmvHtERGdGB5C2VSNqOSBg4Gv2H4cQNLIfqgx2Z4LzAXYctqz3Ob0iIgKNTutQVMq+XVZzZqbw9VMs4yIqFhd67d2oikfP98Hfl/SJpI2p8hHD/AL4MXl42PrKFhExFiK0TUDHW11aEQlb/sG4FKKlMLfYs2Yz48D7y7TF29bU/EiItapn5f/q5TtjwIfHeWp/VoenzFJxYmI6FiTu2saU8lHRKyPMrpmPeUnqkmDqwriTL/rwQpKAkP77FFJHKuiN/T1S6uJU1U63arS+8aUk9E1ERF9yharU8lHRPSvdNdERPSppvfJN/c7xgiStpN0raTFkg6uuzwREcMyhLIarwZutv2uugsSETGsy0VDJl2tLXlJX5V0fbnq+EnlsUdbnj9W0kWSZgHnAkdLWiJpk7rKHBEx0hDqaKtD3S35P7H9QFlpL5T05dFOsr1E0pnAbNunTG4RIyLWzYbV7RcEqU3dlfypkt5UPt6ZYhmrriXVcETUqcndNbVV8pJeCbwGeIntx8sFQqZT3Kwe1lHmyaQajoi6pE9+3bYEHiwr+L2A3yuP3ytpb0nTgDet++UREc1gq6OtDnV211wBnCzpVuA24Cfl8dOBbwD3AYuAGfUULyKiM0lQNgrbK4HXr+Ppy0Y5/yLgogksUkRE1+xm98k395ZwRMR6QQwOTetoaxtJOlzSbZJul3T6KM+fKOm+cij5Eklt5w3VPbqmcrYZWrW6gkDVZDYc+s1ve46hgWpWlBnYcotK4jy17y6VxHnwXb/X/qQObPvZhe1P6kRV2SwroI02qiTO0BNPVBInxlZFf7ukAeAC4LXAcoph5fNsLxtx6qXdDCVPSz4iogfDuWsqSGtwIHC77TtsPwVcAhzda/lSyUdE9MJFv3wnG7CtpEUt20ktkXYE7m7ZX14eG+kYSTdJukzSzu2K13fdNRERk62L0TUrbM/u4VJfB75ge6WkPwMuBl411gtSyUdE9MDljdcK3EMx83/YTuWxNdey72/Z/TRFTq8x1dZdI2m+pK3qun5ERFW66K4Zy0JgpqTdJG0EHA/Maz1B0g4tu0cBt7YLWuc4+TfUde2IiCpVMbrG9mpJpwALgAHgM7aXSjoLWGR7HkW+r6OA1cADwInt4k5KJS/pBOBUYCPgWuDPgf8BZlPMaP0W8APgpRRfT462/YSkPSiGFG0HPA78qe2fTkaZIyI6UbTSq5kMZXs+MH/EsTNbHn8I+FA3MSe8u0bS3sBxwMtszwIGgXeMOG0mcIHtFwAPAceUx+cC77X9YuA04F/XcY2Thu9Wr2LlRPwYERHrNNVXhno18GKKgf0AmwAjZwjdaXtJ+fh6YFdJMyha9l8qXwew8WgXaM1CuYW2SRbKiJhUHfS312YyKnkBF5dfM9YclE5s2W1tfg9SfBBMAx4qW/8REY1kxFCDFw2ZjJJ9FzhW0vYAkraR1HZevO3fAXdKekv5Oknaf2KLGhHRPXe41WHCK/ky78IZwJWSbgK+Deww9que9g7gnZJuBJZSwRTfiIhKOfnksX0pcOmIw7uW/64AXthy7sdbHt8JHD7R5YuI6MkU75OPiOhrdbXSO9GflXyDUsZWoqKfxxXF+fWp1QxTPWe/L1QS54iPPFlNnEOPaX9SJx55rOcQQyvub39SNIKBoaFU8hER/clAWvIREf1rqo+Tj4jobw2u5LseQtkue6SkiyQdO8rxXSW9vWV/tqT/2+31IyKapbPhk3XdnO2qkleRX+BI2w+N41q7Ak9X8rYX2T51HHEiIpqlwbOh2lbyZQv8Nkn/AdwCDEratnzuD8tlqG6U9LmWlx0i6UeS7mhp1X8MOLhcYfz9kl4p6RtlnO0kfVvSUkmflnRXyzVOkHRd+boLy8VuIyKaweAhdbTVodOW/EzgX8sskXcBSHoBxUzWV9neH3hfy/k7AC8HjqSo3AFOB/7b9izb/zwi/t8BV5XxLwOeV16jkwyWERE1U4fb5Ov0xutdtn8y4tirgC/ZXgFg+4GW577qYlD2MknP7iD+y4E3lXGukPRgebyTDJaUi+GeBDCdTTv8kSIiKtLgG6+dVvLdzu5onS3Ty8fXqBksR0qq4YioVYNrnV4SlF0FvEXSs6DILtnm/EeAzdfx3A+Bt5ZxDgO2Lo+PK4NlRMSkGZ4M1clWg3FX8raXAh8FvldmifxEm5fcRHHT9kZJ7x/x3EeAwyTdArwF+A3wSI8ZLCMiJkVFC3lPiLbdNbZ/wdpZIndteXwxcPGI808csT+j/HcVRT9+q2vKfx8GXlcuZPsSYI7tleXrRstgGRHRHBWNnJF0OHA+xULen7b9sXWcdwzFIJU5theNFbMpM16fB3xR0jTgKeBPay5PRETHVEErvRwefgHwWmA5xYCTeWWPRut5m1OMZry2k7iNqORt/xw4oKp4Guh9KL2HqvluVUVZqogBMDRz50ri7HB+NW+bf73z1ZXEOfugnSqJc/6CT1YS57jLe5/j9/yzV1VQEhi6b0UlcRpHFa13VMWfeXUTnQ4Ebrd9B4CkSygWSlo24ry/B84BPthJ0OYuTBgRsV7o8KZr+xuvOwJ3t+wvL4+tuZL0ImBn29/stHSNaMlHRKzXOm/JbyuptQ99bjkEvK2yO/sTwIndFC2VfERErzpfj2eF7dnreO4eoLVPdafy2LDNKQbBXFNODn0OME/SUWPdfE0lHxHRi+oWDVkIzJS0G0XlfjxrJ3V8GNh2eF/SNcBp7UbXTGifvKQTJf1Ll6/5sKTTJqpMERFVkzvbxmJ7NXAKsAC4Ffii7aWSzpJ01HjLlpZ8RESvKproZHs+MH/EsTPXce4rO4k5rpa8pM0kfbOcvXqLpOMkzSnTC99YpgYeTmHwXElXSPq5pHNbYjza8vhYSReNcp09ytdeL+m/Je01nvJGRExV423JHw78yvYRAJK2BBYDx9leKGkL4Iny3FkUY+BXArdJ+qTtu0cLOoq5wMm2fy7pIOBfeeas2WShjIhaVTEZaqKMt5K/GfgnSecA3wAeAn5teyGA7d8BlHeAv1veMEDSMmAX1h4LOipJM4CXAl8q4wBsPNq5yUIZEbUxlaU1mAjjquRt/6wclP8G4B8oMlKuS2va4cGWa7ZWxtNHed004KFysZCIiOZqcNNyvH3yzwUet/154DzgIGAHSXPK5zeX1O4D5F5Je5cD/N808sny28Cdkt5SxpSk/cdT3oiIiVTF6JqJMt7umn2B8yQNAauAd1Ms8PFJSZtQ9Me/pk2M0ym6eu4DFgEzRjnnHcC/SToD2BC4BLhxnGWOiJgYDW7Jj7e7ZgHFWM6Rfm/E/kXlNvy6I1seX0aRKnNk7A+3PL6T4iZvRERz9VslHxERhTq7YjrRd5W8BgaYtvm6VhnsnJ94soLSgKaPOiCoK0Mzn1dBSWDW/7upkjg3v3WPSuIM3vPrSuJs9qXllcQ542svqyTO8zf/Wc8xVs+sJn0y/Zpq2J0ni5kU/Ta6JiIi1khLPiKin6WSj4joUw3vk5+0laEkXSTp2Mm6XkTEpHGHWw3Sko+I6JEadh+4VU8teUl/K+k2ST+Q9AVJp7XJHHlImanyjtZWvaQPSloo6SZJHymP7SrpVkmfkrRU0pXlRKuIiOjQuCv5MoXBMcD+wOuB4SWt5gLvtf1i4DSKzJHDdgBeDhwJfKyMcxgwk2Kl8lnAiyUdUp4/E7jA9gsokqAdM97yRkRMmD7trnkZ8DXbTwJPSvo6RaKxsTJHftX2ELBM0rPLY4eV2+JyfwZF5f5L4E7bS8rj1wO7jlaQtVINTxstO0JExARp+I3Xqvvk22WObM1IqZZ/z7Z9YeuJknblmRksR+2uaU01vOUG2zX41x0RfanBtU4vffI/BN4oaXqZ+/1I4HG6zxy5APiTMgaSdpS0fQ/lioiYXP3YXVOuADUPuAm4l2IhkYfpMnOk7Ssl7Q38uOzieRQ4gaLlHhHRaKLZo2t67a75uO0PS9oU+D5w/boyR9o+ccT+jJbH5wPnjxL/hS3nfLzHskZEVK/CPnlJh1PUhQPAp21/bMTzJwPvoWgEPwqcZHvZWDF7nQw1V9IS4Abgy7Zv6DFeRMT6p4LuGkkDwAUUoxX3Ad4maZ8Rp/2X7X3L+57nAp9oV7SeWvK2397L6yeCBwcZfOihuouxxsoKslkuurn3GMDiAyoJA7qzokDVmLZpNYu3e59qsmve9vbeR3g9q5qEoWx1bUWT2puW9VFV/VzVhKkozoHA7bbvAJB0CXA08HRLfXj97NJmnVw5M14jInrURXfNtpIWtezPLUcHAuwI3N3y3HKKpVXXvpb0HuADwEbAq9pdMJV8RESvOq/kV9ie3f60MS5lXwBcIOntwBnAH411fir5iIheuLLRNfcAO7fs71QeW5dLgH9rF3TSslBGRPStasbJLwRmStpN0kbA8cC81hMkzWzZPQL4ebugaclHRPSoiiGUtldLOoVigugA8BnbSyWdBSyyPQ84RdJrgFXAg7TpqoFU8hERvatolDAG3dkAAAmRSURBVI7t+cD8EcfObHn8vm5jppKPiOhFjSkLOtEXlfxaWSipZsx0REQnxNTKQlmL1iyUW2ibBv+6I6IfpZKPiOhnDa7k17shlJK+K2nHussREfG0fkw1XAdJ04D/BTxQd1kiIoAptzLURNuHItvlE3UXJCLiaankq2H7ForEPBERjdHPi4ZEjF9F6WuHnqggnTOwwQOPVBLn+ef3nur6/kN2qqAk8OhxB1YSZ8tv3FJJHD1r60rirNy9ohVCr/piJWHSXRMR0a8yGSoios+lko+I6E+Z8RoR0ec01Nxafr2ZDCXpF5J2lXRN3WWJiHhapxOhMhkqImL9lO6aatwHDJLZrhHRNKnke2d7TvnwzSOfS6rhiKhTk1vy602f/Fhsz7U92/bsDdm47uJExFSTPvmIiD7lpDWIiOhbTR8n3xfdNRERtbI729qQdLik2yTdLun0UZ7/gKRlkm4q19bYpV3MVPIRET2SO9vGjCENABcAr6dIq/42SfuMOG0xMNv2fsBlwLntytaf3TWq4LOrogyJfalpv5uKyrP6jl9UEmeD7bbtOcbgxqqgJNX55an7VRJnl0t+VUmcjX96TyVxKlHdTdUDgdtt3wEg6RLgaGDZ05eyr245/yfACe2C9mclHxExibq48bqtpEUt+3Ntzy0f7wjc3fLccuCgMWK9E/hWuwumko+I6FEXlfwK27N7vp50AjAbeEW7c1PJR0T0wnR0U7UD9wA7t+zvVB5bi6TXAH8DvML2ynZBc+M1IqJHVdx4BRYCMyXtJmkj4Hhg3lrXkQ4ALgSOsv3bTsrWqEpe0ixJb6i7HBERXalgxqvt1cApwALgVuCLtpdKOkvSUeVp5wEzgC9JWiJp3jrCPa1p3TWzKPqZ5tddkIiITlQ5Gcr2fEbUf7bPbHn8mm5jVtaSl7SZpG9KulHSLZKOk3SmpIXl/lxJKs+dUw7mXyLpvPL5jYCzgOPK48eVMT8j6TpJiyUdXVV5IyIqYaOhzrY6VNldczjwK9v7234hcAXwL7bnlPubAEeW534W+DPbsyjSB2P7KeBM4FLbs2xfSnFz4SrbBwKHAudJ2mzkhSWdJGmRpEWraHsfIiKiWg1OUFZlJX8z8FpJ50g62PbDwKGSrpV0M/Aq4AWStgI2t/3j8nX/NUbMw4DTJS0BrgGmA88beVKyUEZEnSq68TohKuuTt/0zSS8C3gD8g6TvAu+hmIJ7t6QPU1TS3RBwjO3bqipnRESlDEyFNV4lPRd43PbnKe4Av6h8aoWkGcCxALYfAh6RNDyT6/iWMI8Am7fsLwDe29KXf0BV5Y2IqEyDu2uqHF2zL0Wf+RCwCng38PvALcBvKMaADnsn8Kny3O8BD5fHr2ZN98zZwN8D/we4SdI04E7W9OtHRDRCk1MNV9lds4Ci5d1qEXDGKKcvLbOoUabTXFTGeACYM+LcP6uqjBERE6GukTOdqGuc/BGSPlRe/y7gxJrKERHRmxq7YjpRSyVfDo+8dOIu0LBUuA2hgYFK4riqVkvT/p+qSFENDD32eM8xtv/23e1P6sCtH9m+kjgb/KaiUWtVvQcffaySOFUoJkM1t5Zv2ozXiIj1T8PaK61SyUdE9Cgt+YiIfpU++YiIflZfXppOrJeVvKQB24N1lyMiAqhq0ZAJ0ah88sMknVBmnlwi6UJJA5IelfRPkm4EXlJ3GSMiAHCx/F8nWx0aV8lL2hs4DnhZS5bKdwCbAdeWWS5/UGcZIyLWYne21aCJ3TWvBl4MLCxT1mwC/Jaisv/yaC+QdBJwEsB0Np2cUkZEDGtub00jK3kBF9v+0FoHpdPW1Q9vey4wF2ALbdPgX3dE9CMNNXegfOO6a4DvAsdK2h5A0jaSdqm5TBERozPFZKhOtho0riVve5mkM4Ary8yTqyjy0kdENI5woydDNbElj+3hJQD3s/1i2z+xPaPuckVEjKqiG6+SDpd0m6Tbywy9I58/RNINklZLOraTojWyko+IWK9UUMlLGgAuAF4P7AO8TdI+I077JUXW3rGWTV1L47prYuJ4MPPHxlRRVsyhx3vPQjn0yycrKAns/derK4mzao/nVBLn1g9tXUmcvc9RJXH4XQUxhvvke3cgcLvtOwAkXQIcDSx7+lL2L8rnOr5iKvmIiB51MbpmW0mLWvbnlqMDAXYEWnNMLwcOokep5CMietLVRKcVtmdPZGlGSiUfEdELU9Vs1nuAnVv2dyqP9SQ3XiMielXNOPmFwExJu0naCDgemNdr0VLJR0T0SHZH21hsrwZOARYAtwJftL1U0lmSjgKQNEfScuAtwIWSlrYrW7prIiJ6VdFkKNvzgfkjjp3Z8nghRTdOx1LJR0T0wobB5uau6YtKPlkoI6JWDU5r0BeVfLJQRkStUslHRPQpA1njNSKiX7mylBgTYb0aQilpvqTn1l2OiIinmeLGaydbDdarlrztN9RdhoiIZ0iffEREH0slP4kktMGGPYfx6lUVFCamIg0MVBCkop7UTaZXEmbVjGqqig1/0/vfJsBfzP9aJXGu2L2KKF0lKJt0/VfJR0RMJgMNXsg7lXxERK/Sko+I6FdJazAqSccDe9j+aF1liIjomcEZJw+SNpK0Wcuh1wNXdHhuRERzDbmzrQYTXslL2lvSPwG3AXuWxwTMAm6Q9ApJS8ptsaTNga2BpZIulDRnossYEdETu7OtBhNSyUvaTNIfS/oB8CmK1cb3s724POUA4EbbBk4D3mN7FnAw8ITte4HnA1cDHy0r/1MlbTMR5Y2IGDe7GF3TyVaDieqT/zVwE/Au2z8d5fnDgW+Vj38IfELSfwKX214OYHslcAlwiaTnAf8CnCtpd9u/ag2WVMMRUasGj66ZqO6aYykWoL1c0pmSdhnx/GHAlQC2Pwa8C9gE+KGkvYZPkrS9pL8Evg4MAG8H7h15Mdtzbc+2PXtDVTP5IyKiM8aDgx1tdZiQlrztK4ErJT0LOAH4mqQVFJX5g8AGtu8HkLSH7ZuBm8v+970k/Rq4GNgL+BzwBts9r1oeEVG5qZxquKzIzwfOl3QgMAi8FvhOy2l/IelQirXMl1J040wH/i9wddlvHxHRXA0eQjlp4+RtXwcg6e+AT7ccf+8op68ErpqkokVEjJsBT9WW/Ghsv2uyrxkRMWHc7EVDktYgIqJHdd1U7YT6rctb0n3AXXWXIyLWC7vY3q6XAJKuALbt8PQVtg/v5Xrd6rtKPiIi1liv1niNiIjupJKPiOhjqeQjIvpYKvmIiD6WSj4ioo/9f9AcWvdAb9p7AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qXou7F2agYmw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}